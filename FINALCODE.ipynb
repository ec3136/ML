{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINALCODE",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ec3136/ML/blob/master/FINALCODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbXpeHIWN5YO",
        "colab_type": "code",
        "outputId": "d3c36a2b-4994-402e-9854-81f0289dc30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default() \n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145605 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.14-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.14-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM0VGHyGLs-H",
        "colab_type": "code",
        "outputId": "9228ed76-878e-4576-9f9f-b5ba022ca758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG66p6fcoaBo",
        "colab_type": "code",
        "outputId": "eb551684-1ce1-428e-d23f-35d02381828b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "# Install TF 2.0 preview CPU version\n",
        "# Install tf 2.0 preview GPU version\n",
        "!pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly-gpu-2.0-preview in /usr/local/lib/python3.6/dist-packages (2.0.0.dev20191002)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (2.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (0.33.6)\n",
            "Requirement already satisfied: tb-nightly<2.2.0a0,>=2.1.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (2.1.0a20191206)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu-2.0-preview) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly-gpu-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (42.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.16.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.2.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.2.0a0,>=2.1.0a0->tf-nightly-gpu-2.0-preview) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3xNlsYaTKne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppC23F7P0_sm",
        "colab_type": "code",
        "outputId": "d12d78ba-3b07-4c21-b31c-e131fcb39ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import os\n",
        "!pip show tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: six, opt-einsum, termcolor, tensorflow-estimator, tensorboard, keras-preprocessing, wrapt, google-pasta, protobuf, astor, wheel, keras-applications, numpy, absl-py, gast, grpcio\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAUUMCChlDjx",
        "colab_type": "code",
        "outputId": "1d991b7a-2eb3-4b27-c473-d4a7dc4cc2c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "pip install --upgrade tensorflow-gpu==1.4\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-gpu==1.4 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.1.6)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.4) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (0.9999999)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (1.5.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow-gpu==1.4) (42.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXBoRh30pXJw",
        "colab_type": "code",
        "outputId": "a1384298-675f-4a69-88b1-6c6377323195",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip show keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: Keras\n",
            "Version: 2.2.5\n",
            "Summary: Deep Learning for humans\n",
            "Home-page: https://github.com/keras-team/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: keras-preprocessing, keras-applications, six, pyyaml, numpy, scipy, h5py\n",
            "Required-by: textgenrnn, keras-vis, kapre, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr0cy0uC1GOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/BRATS-2/Image_Data/HG')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC0yym6b1Kwq",
        "colab_type": "code",
        "outputId": "6c97c6d8-3295-45ce-f6a4-afac156a41dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip3 install SimpleITK\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 211kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K82XkNZ91OOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NrSUPU41R4Y",
        "colab_type": "code",
        "outputId": "8648acde-0647-4a89-9f49-7aff2785c575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "path = '/content/drive/My Drive/BRATS-2/Image_Data/LG/0002'\n",
        "p = os.listdir(path)\n",
        "p.sort(key=str.lower)\n",
        "arr=[]\n",
        "\n",
        "for i in range(len(p)):\n",
        "  if 'more' in p[i] or 'OT' in p[i]:\n",
        "    if p[i] != '.DS_Store':\n",
        "      p1 = os.listdir(path+'/'+p[i])\n",
        "      img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "      Y_labels = sitk.GetArrayFromImage(img) \n",
        "      print(Y_labels.shape)\n",
        "  else:\n",
        "    if p[i] != '.DS_Store':\n",
        "      p1 = os.listdir(path+'/'+p[i])\n",
        "      p1.sort()\n",
        "      img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "      arr.append(sitk.GetArrayFromImage(img))\n",
        "      \n",
        "data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "for i in range(Y_labels.shape[1]):\n",
        "  data[i,:,:,0] = arr[0][:,i,:]\n",
        "  data[i,:,:,1] = arr[1][:,i,:]\n",
        "  data[i,:,:,2] = arr[2][:,i,:]\n",
        "  data[i,:,:,3] = arr[3][:,i,:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(176, 236, 216)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmPK1pTOrQW",
        "colab_type": "code",
        "outputId": "9f967388-0284-4e0f-dcb9-b56ad9e60f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        }
      },
      "source": [
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "img = data[126,:,:,0]\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "plt.imsave('slice_126_4',img,cmap='gray')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAD8CAYAAAAbkUOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1910\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6468d5474c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice_126_4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[1;32m   2131\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1911\u001b[0m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown file extension: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown file extension: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W3vzSA7OzD2",
        "colab_type": "code",
        "outputId": "ac0d9f64-421a-4651-930a-7b7bc053e13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "img = Y_labels[:,126,:]\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "#plt.imsave('slice_126_GT',img,cmap='gray')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAD8CAYAAAAbkUOLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpYEh5mZJcFhZmZJcJiZWRL+H3P0yrhvROvVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT_xNOTsPC14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_gen(input_dim,x,y,slice_no):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "  Y = []\n",
        "  \n",
        "  for i in range(int((input_dim)/2),y.shape[0]-int((input_dim)/2)):\n",
        "    for j in range(int((input_dim)/2),y.shape[2]-int((input_dim)/2)):\n",
        "      #Filtering all 0 patches\n",
        "      if(x[i-16:i+17,j-16:j+17,:].any != 0):\n",
        "        X2.append(x[i-16:i+17,j-16:j+17,:])\n",
        "        X1.append(x[i-int((input_dim)/2):i+int((input_dim)/2)+1,j-int((input_dim)/2):j+int((input_dim)/2)+1,:])\n",
        "        Y.append(y[i,slice_no,j])\n",
        "      \n",
        "      \n",
        "  X1 = np.asarray(X1)\n",
        "  X2 = np.asarray(X2)\n",
        "  Y = np.asarray(Y)\n",
        "  d = [X1,X2,Y]\n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2MsaLYPPG7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(data,y,slice_no,model_no):\n",
        "  d = []\n",
        "  x = data[slice_no]\n",
        "  #filtering all 0 slices and non-tumor slices\n",
        "  if(x.any() != 0 and y.any() != 0):\n",
        "    if(model_no == 0):\n",
        "      X1 = []\n",
        "      for i in range(16,159):\n",
        "        for j in range(16,199):\n",
        "          if(x[i-16:i+17,j-16:j+17,:].all != 0):\n",
        "            X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "      Y1 = []\n",
        "      for i in range(16,159):\n",
        "        for j in range(16,199):\n",
        "          if(x[i-16:i+17,j-16:j+17,:].all != 0):\n",
        "            Y1.append(y[i,slice_no,j]) \n",
        "      X1 = np.asarray(X1)\n",
        "      Y1 = np.asarray(Y1)\n",
        "      d = [X1,Y1]\n",
        "    elif(model_no == 1):\n",
        "      d = model_gen(65,x,y,slice_no)\n",
        "    elif(model_no == 2):\n",
        "      d = model_gen(56,x,y,slice_no)\n",
        "    elif(model_no == 3):\n",
        "      d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvPx2quh8Ree",
        "colab_type": "code",
        "outputId": "a4fb709a-ac64-4db1-a33c-bfe9da15c56c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: bazel: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs-K3wtfPwOA",
        "colab_type": "code",
        "outputId": "2021b69a-65a5-45d5-cba3-96ae14c53ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
        "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.initializers import glorot_normal\n",
        "#import pydot\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuky77UKPK7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def two_path(X_input):\n",
        "\n",
        "  X = Conv2D(64,(7,7),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01) )(X_input)\n",
        "\n",
        "\n",
        "  X = BatchNormalization()(X)\n",
        "  X1 = Conv2D(64,(7,7),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X1 = BatchNormalization()(X1)\n",
        "  # Max-out\n",
        "  X = layers.Maximum()([X,X1])\n",
        "  X = layers.Dropout(.5)(X)\n",
        "  X = Conv2D(64,(4,4),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  \n",
        "\n",
        "  X2 = Conv2D(160,(13,13),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X2 = BatchNormalization()(X2)\n",
        "  X21 = Conv2D(160,(13,13),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X_input)\n",
        "  X21 = BatchNormalization()(X21)\n",
        "\n",
        "  X2 = layers.Maximum()([X2,X21])\n",
        "  X2 = layers.Dropout(.5)(X2)\n",
        "\n",
        "  \n",
        "\n",
        "  X3 = Conv2D(64,(3,3),strides=(1,1),padding='valid', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  X3 = BatchNormalization()(X3)\n",
        "  X31 =  Conv2D(64,(3,3),strides=(1,1),padding='valid',  kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  X31 = BatchNormalization()(X31)\n",
        "  X = layers.Maximum()([X3,X31])\n",
        "  X = layers.Dropout(.5)(X)\n",
        "\n",
        "  X = Conv2D(64,(2,2),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X)\n",
        "  \n",
        "  X = Concatenate()([X2,X])\n",
        "\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFKFL29MYhdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYyw0QiPNuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_cascade(input_shape1,input_shape2):\n",
        "  \n",
        "  X1_input = Input(input_shape1)\n",
        "\n",
        "\n",
        "  X1 = two_path(X1_input)\n",
        "  X1 = Conv2D(5,(21,21),strides=(1,1),padding='valid',activation='relu', kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X1)\n",
        "  X1 = BatchNormalization()(X1)\n",
        "  \n",
        "  X2_input = Input(input_shape2)\n",
        "\n",
        "\n",
        "  X2_input1 = Concatenate()([X1,X2_input])\n",
        "  X2 = two_path(X2_input1)\n",
        "  \n",
        "\n",
        "  X2 = Conv2D(5,(21,21),strides=(1,1),padding='valid',  kernel_regularizer=regularizers.l2(0.01),\n",
        "               activity_regularizer=regularizers.l1(0.01))(X2)\n",
        "  X2 = BatchNormalization()(X2)\n",
        "\n",
        "\n",
        "  X2 = Activation('softmax')(X2)\n",
        "  \n",
        "  model = Model(inputs=[X1_input,X2_input],outputs=X2)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6BcUMstPl6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_REgVjdPnzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHYmqoHRP9d9",
        "colab_type": "code",
        "outputId": "4e090784-2e03-4434-9b36-06f33cbd00f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "m1 = input_cascade((65,65,4),(33,33,4))\n",
        "m1.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 65, 65, 4)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 59, 59, 64)   12608       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 59, 59, 64)   12608       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 59, 59, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 59, 59, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "maximum (Maximum)               (None, 59, 59, 64)   0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 59, 59, 64)   0           maximum[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 56, 56, 64)   65600       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 54, 54, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 54, 54, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 53, 53, 160)  108320      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 53, 53, 160)  108320      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 54, 54, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 53, 53, 160)  640         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 53, 53, 160)  640         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "maximum_2 (Maximum)             (None, 54, 54, 64)   0           batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "maximum_1 (Maximum)             (None, 53, 53, 160)  0           batch_normalization_2[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 54, 54, 64)   0           maximum_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 53, 53, 160)  0           maximum_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 53, 53, 64)   16448       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 53, 53, 224)  0           dropout_1[0][0]                  \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 33, 33, 5)    493925      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 33, 33, 5)    20          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 33, 33, 4)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33, 33, 9)    0           batch_normalization_6[0][0]      \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 27, 27, 64)   28288       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 27, 27, 64)   28288       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 27, 27, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 27, 27, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "maximum_3 (Maximum)             (None, 27, 27, 64)   0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 27, 27, 64)   0           maximum_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 24, 24, 64)   65600       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 22, 22, 64)   36928       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 22, 22, 64)   36928       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 21, 21, 160)  243520      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 21, 21, 160)  243520      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 22, 22, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 22, 22, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 21, 21, 160)  640         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 21, 21, 160)  640         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "maximum_5 (Maximum)             (None, 22, 22, 64)   0           batch_normalization_11[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "maximum_4 (Maximum)             (None, 21, 21, 160)  0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 22, 22, 64)   0           maximum_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 21, 21, 160)  0           maximum_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 21, 21, 64)   16448       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 21, 21, 224)  0           dropout_4[0][0]                  \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 1, 1, 5)      493925      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 1, 1, 5)      20          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1, 1, 5)      0           batch_normalization_13[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 2,089,778\n",
            "Trainable params: 2,087,454\n",
            "Non-trainable params: 2,324\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssep_-drQnV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GjyGadWJ8QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "import keras.backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNt6V30zq1ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJqU1X5o05Y",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr4DkGNQJhMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7YI97-ST_Z-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen_hg(path,slice_no,model_no):\n",
        "  p = os.listdir(path)\n",
        "  p.sort(key=str.lower)\n",
        "  arr = []\n",
        "  for i in range(len(p)):\n",
        "    if 'more' in p[i] or 'OT' in p[i]:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "        y = sitk.GetArrayFromImage(img)    \n",
        "\n",
        "    else:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        p1.sort()\n",
        "        img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "        arr.append(sitk.GetArrayFromImage(img))\n",
        "  data = np.zeros((196,176,160,4))\n",
        "  for i in range(196):\n",
        "    data[i,:,:,0] = arr[0][:,i,:]\n",
        "    data[i,:,:,1] = arr[1][:,i,:]\n",
        "    data[i,:,:,2] = arr[2][:,i,:]\n",
        "    data[i,:,:,3] = arr[3][:,i,:]\n",
        "  x = data[slice_no]\n",
        "  \n",
        "  if(model_no == 0):\n",
        "    X1 = []\n",
        "    for i in range(16,159):\n",
        "      for j in range(16,199):\n",
        "        X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "    Y1 = []\n",
        "    for i in range(16,159):\n",
        "      for j in range(16,199):\n",
        "        Y1.append(y[i,slice_no,j]) \n",
        "    X1 = np.asarray(X1)\n",
        "    Y1 = np.asarray(Y1)\n",
        "    d = [X1,Y1]\n",
        "  elif(model_no == 1):\n",
        "    d = model_gen(65,x,y,slice_no)\n",
        "  elif(model_no == 2):\n",
        "    d = model_gen(56,x,y,slice_no)\n",
        "  elif(model_no == 3):\n",
        "    d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhiHDLerGDlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen_lg(path,slice_no,model_no):\n",
        "  p = os.listdir(path)\n",
        "  p.sort(key=str.lower)\n",
        "  arr = []\n",
        "  for i in range(len(p)):\n",
        "    if 'more' in p[i] or 'OT' in p[i]:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "        y = sitk.GetArrayFromImage(img)    \n",
        "\n",
        "    else:\n",
        "      if p[i] != '.DS_Store':\n",
        "        p1 = os.listdir(path+'/'+p[i])\n",
        "        p1.sort()\n",
        "        img = sitk.ReadImage(path + '/' + p[i]+'/'+p1[-1])\n",
        "        arr.append(sitk.GetArrayFromImage(img))\n",
        "  data = np.zeros((196,176,216,4))\n",
        "  for i in range(196):\n",
        "    data[i,:,:,0] = arr[0][:,i,:]\n",
        "    data[i,:,:,1] = arr[1][:,i,:]\n",
        "    data[i,:,:,2] = arr[2][:,i,:]\n",
        "    data[i,:,:,3] = arr[3][:,i,:]\n",
        "  x = data[slice_no]\n",
        "  \n",
        "  if(model_no == 0):\n",
        "    X1 = []\n",
        "    for i in range(16,215):\n",
        "      for j in range(16,199):\n",
        "        X1.append(x[i-16:i+17,j-16:j+17,:])\n",
        "    Y1 = []\n",
        "    for i in range(16,215):\n",
        "      for j in range(16,199):\n",
        "        Y1.append(y[i,slice_no,j]) \n",
        "    X1 = np.asarray(X1)\n",
        "    Y1 = np.asarray(Y1)\n",
        "    d = [X1,Y1]\n",
        "  elif(model_no == 1):\n",
        "    d = model_gen(65,x,y,slice_no)\n",
        "  elif(model_no == 2):\n",
        "    d = model_gen(56,x,y,slice_no)\n",
        "  elif(model_no == 3):\n",
        "    d = model_gen(53,x,y,slice_no)  \n",
        "    \n",
        "  return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4w6cmkXqQGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = data_gen_lg('/content/drive/My Drive/BRATS-2/Image_Data/LG/0001',100,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Oj1sGfnVcdR",
        "colab_type": "code",
        "outputId": "e095ba08-1729-4ae2-aa52-cc153b67afca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(d[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNC1oIzH4vwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# d = []\n",
        "\n",
        "# for i in range(1,3):\n",
        "#   path = '/content/drive/My Drive/BRATS-2/Image_Data/LG/000' + str(i)\n",
        "#   d.append(data_gen_lg(path, 100,1))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCbPAuBrcbZE",
        "colab_type": "code",
        "outputId": "70866f36-9943-4873-c320-28876059e443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "y = np.zeros((17024,1,1,5))\n",
        "\n",
        "for i in range(y.shape[0]):\n",
        "  y[i,:,:,d[2][i]] = 1\n",
        "\n",
        "\n",
        "sample = np.zeros((5,1))\n",
        "for i in range(5):\n",
        "  sample[i] = np.sum(y[:,:,:,i])\n",
        "print(sample/np.sum(sample))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.61231203e-01]\n",
            " [2.13228383e-02]\n",
            " [4.34680451e-03]\n",
            " [1.25117481e-02]\n",
            " [5.87406015e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIur16G9JdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for i in range(4,6):\n",
        "#   path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/000' + str(i)\n",
        "#   d.append(data_gen_hg(path, 100,1))\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kleu1c09s28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lengths_d = []\n",
        "# for i in range(len(d)):\n",
        "#   lengths_d.append(len(d[i][0]))\n",
        "# print(lengths_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ImcKgeTVkZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y = []\n",
        "# for i in range(len(lengths_d)):\n",
        "#   y.append(np.zeros((lengths_d[i],1,1,5)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM1S06snVqt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for j in range(len(d)):\n",
        "#   for i in range(y[j].shape[0]):\n",
        "#     y[j][i,:,:,d[j][2][i]] = 1\n",
        "#   sample = np.zeros((5,1))\n",
        "#   for i in range(5):\n",
        "#     sample[i] = np.sum(y[j][:,:,:,i])\n",
        "#   print(sample/np.sum(sample))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxCdJIZDVyCW",
        "colab_type": "code",
        "outputId": "36415fdc-8432-49ab-ebae-b02a51dc6225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X1 = np.asarray(d[0])\n",
        "X1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17024, 65, 65, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBYXUckLTuwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrJ6E48eVMDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3lxc6ChUb4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# for i in range(len(d)):\n",
        "\n",
        "#     # Create the model based on the model type\n",
        "#     # Create the optimizer\n",
        "#     sgd = optimizers.SGD(lr=.005)\n",
        "\n",
        "\n",
        "#     X1 = np.asarray(d[i][0])\n",
        "#     X2 = np.asarray(d[i][1])\n",
        "\n",
        "#     class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                  np.unique(d[i][2]),\n",
        "#                                                  d[i][2])\n",
        "#     m1.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy',f1])\n",
        "\n",
        "#         # Compute quantities required for feature-wise normalization\n",
        "#         # (std, mean, and principal components if ZCA whitening is applied).\n",
        "\n",
        "#         # Fit the model on the batches generated by datagen.flow().\n",
        "#     m1_info = m1.fit([X1,X2],y[i],epochs=20,batch_size=256,class_weight = class_weights)\n",
        "\n",
        "#     m1.save('trial_InputCascade_acc.h5'+ i)\n",
        "\n",
        "#     # Save model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io-L_25ZVyLE",
        "colab_type": "code",
        "outputId": "9226783e-67d6-4529-d83c-9db3bdd29242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X2 = np.asarray(d[1])\n",
        "X2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17024, 33, 33, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaYhWGmASZTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HvhUQSKeYD2",
        "colab_type": "code",
        "outputId": "9f10a41f-6e10-4a9c-9fd6-6daf1798e5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(d[2]),\n",
        "                                                 d[2])\n",
        "\n",
        "class_weights\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.08066487e-01, 9.37961433e+00, 4.60108108e+01, 1.59849765e+01,\n",
              "       3.40480000e+02])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyMaS5lKV-IE",
        "colab_type": "code",
        "outputId": "7aec70ce-81c4-49a0-e7ab-22239bbc664b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m1.input_shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(None, 65, 65, 4), (None, 33, 33, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWzLjRGC8BKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2jJdEDF2Z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAhIjiTgF4Kd",
        "colab_type": "code",
        "outputId": "deb105f8-32bd-45a7-f194-5501cf910392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#K.clear_session()\n",
        "print(X2.sum())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11776462582.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5j5CIxK8C_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m0.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy', f1])\n",
        "# m0_info = m0.fit(X2,y,epochs=100,batch_size=1024,class_weight = class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgmX8Cj68Rp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "sgd = tf.keras.optimizers.SGD(lr=.001, decay=.01, momentum=.9, clipnorm=1)\n",
        "m1.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy',f1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56sTPTKkxpcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpqersxmFLH8",
        "colab_type": "code",
        "outputId": "2fa07ddb-07ff-4733-afa4-5f3a3e798d22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "m1_info = m1.fit([X1,X2],y,epochs=20,batch_size=256,class_weight = class_weights)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 10752 samples\n",
            "Epoch 1/20\n",
            "10752/10752 [==============================] - 35s 3ms/sample - loss: 618376.0060 - acc: 0.4680 - f1: 0.2319\n",
            "Epoch 2/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 289345.4219 - acc: 0.7472 - f1: 0.3743\n",
            "Epoch 3/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 212796.1161 - acc: 0.6785 - f1: 0.4789\n",
            "Epoch 4/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 171972.6648 - acc: 0.6659 - f1: 0.4971\n",
            "Epoch 5/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 147746.9866 - acc: 0.6741 - f1: 0.5156\n",
            "Epoch 6/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 132072.4243 - acc: 0.7099 - f1: 0.5463\n",
            "Epoch 7/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 121005.1382 - acc: 0.7314 - f1: 0.5773\n",
            "Epoch 8/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 112397.2959 - acc: 0.7420 - f1: 0.5907\n",
            "Epoch 9/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 105683.8770 - acc: 0.7580 - f1: 0.6043\n",
            "Epoch 10/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 100177.8752 - acc: 0.7691 - f1: 0.6127\n",
            "Epoch 11/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 95564.7011 - acc: 0.7711 - f1: 0.6270\n",
            "Epoch 12/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 91559.3544 - acc: 0.7837 - f1: 0.6373\n",
            "Epoch 13/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 87974.0253 - acc: 0.7880 - f1: 0.6458\n",
            "Epoch 14/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 84829.6549 - acc: 0.7878 - f1: 0.6518\n",
            "Epoch 15/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 82130.5872 - acc: 0.7973 - f1: 0.6567\n",
            "Epoch 16/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 79690.8378 - acc: 0.7992 - f1: 0.6625\n",
            "Epoch 17/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 77424.9392 - acc: 0.8013 - f1: 0.6676\n",
            "Epoch 18/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 75332.2468 - acc: 0.8000 - f1: 0.6731\n",
            "Epoch 19/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 73438.8666 - acc: 0.8039 - f1: 0.6738\n",
            "Epoch 20/20\n",
            "10752/10752 [==============================] - 26s 2ms/sample - loss: 71721.8132 - acc: 0.8093 - f1: 0.6806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s-D6eiBXYVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "m1.save('trial_InputCascade_acc.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkqCARxZ9Ibp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.losses\n",
        "keras.losses.custom_loss = f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l2ft5Hk4OJt",
        "colab_type": "code",
        "outputId": "f76b18d8-58f2-4e99-ed48-da5838dbb265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "m1 = tf.keras.models.load_model('trial_InputCascade_acc.h5', custom_objects={'f1': f1})\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22jJSWNTVjjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# info = []\n",
        "# for i in range(0,data.shape[0]):\n",
        "#   d = data_gen(data,Y_labels,i,3)\n",
        "#   if(len(d) != 0):\n",
        "#     y = np.zeros((d[2].shape[0],1,1,5))\n",
        "#     for j in range(y.shape[0]):\n",
        "#       y[j,:,:,d[2][j]] = 1\n",
        "#     X1 = d[0]\n",
        "#     X2 = d[1]\n",
        "#     class_weights = class_weight.compute_class_weight('balanced',\n",
        "#                                                       np.unique(d[2]),\n",
        "#                                                       d[2])\n",
        "#     print('slice no:'+str(i))\n",
        "#     info.append(m1.evaluate([X1,X2],y,batch_size=256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gEcLsnjP0Qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwUbJ6pCqXfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "hf = h5py.File('info1_input.h5', 'w')\n",
        "hf.create_dataset('dataset_1', data=info)\n",
        "hf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC_BQb06JEEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hf = h5py.File('info1_input.h5', 'r')\n",
        "X = hf.get('dataset_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIoo1Y-KJBCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIL_qdsRShaX",
        "colab_type": "code",
        "outputId": "ec2c216a-3933-4e1d-d68d-a36cb44f3548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fold = os.listdir('/content/drive/My Drive/BRATS-2/Image_Data/HG/')\n",
        "fold.sort(key=str.lower) \n",
        "fold = fold[:3]\n",
        "for path in fold:\n",
        "    print(path)\n",
        "    path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/'+path\n",
        "    p = os.listdir(path)\n",
        "    p.sort(key=str.lower)\n",
        "    arr = []\n",
        "    \n",
        "    # Reading from 4 images and creating 4 channel slice-wise \n",
        "    for i in range(len(p)):\n",
        "      if 'more' in p[i] or 'OT' in p[i]:\n",
        "        if p[i] != '.DS_Store':\n",
        "          p1 = os.listdir(path+'/'+p[i])\n",
        "          img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "          Y_labels = sitk.GetArrayFromImage(img) \n",
        "      else:\n",
        "        if p[i] != '.DS_Store':\n",
        "          p1 = os.listdir(path+'/'+p[i])\n",
        "          p1.sort()\n",
        "          img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])\n",
        "          arr.append(sitk.GetArrayFromImage(img))\n",
        "    data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "    for i in range(Y_labels.shape[1]):\n",
        "      data[i,:,:,0] = arr[0][:,i,:]\n",
        "      data[i,:,:,1] = arr[1][:,i,:]\n",
        "      data[i,:,:,2] = arr[2][:,i,:]\n",
        "      data[i,:,:,3] = arr[3][:,i,:]\n",
        "    print(data.shape)\n",
        "    info = []\n",
        "    print(data.shape[0])\n",
        "    # Creating patches for each slice and training(slice-wise)\n",
        "    for i in range(data.shape[0]):\n",
        "      d = data_gen(data,Y_labels,i,1)\n",
        "      if(len(d) != 0):\n",
        "        y = np.zeros((d[2].shape[0],1,1,5))\n",
        "        for j in range(y.shape[0]):\n",
        "          y[j,:,:,d[2][j]] = 1\n",
        "        X1 = d[0]\n",
        "        X2 = d[1]\n",
        "        class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                          np.unique(d[2]),\n",
        "                                                          d[2])\n",
        "        print('slice no:'+str(i))\n",
        "        info.append(m1.fit([X1,X2],y,epochs=5,batch_size=128,class_weight= class_weights))\n",
        "        m1.save('trial_InputCascade_acc_lg001.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0001\n",
            "(216, 176, 160, 4)\n",
            "216\n",
            "slice no:20\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 34s 3ms/sample - loss: 60201.8048 - acc: 0.6943 - f1: 0.0329\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 31972.0254 - acc: 0.8874 - f1: 0.0555\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 23352.0498 - acc: 0.9183 - f1: 0.0918\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 18700.5515 - acc: 0.9334 - f1: 0.1339\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15798.2945 - acc: 0.9475 - f1: 0.1971\n",
            "slice no:21\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16936.8409 - acc: 0.9509 - f1: 0.6713\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14707.5448 - acc: 0.9578 - f1: 0.9120\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13194.3977 - acc: 0.9614 - f1: 0.9224\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12113.9611 - acc: 0.9670 - f1: 0.9357\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11296.8062 - acc: 0.9687 - f1: 0.9383\n",
            "slice no:22\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15459.5615 - acc: 0.9655 - f1: 0.9367\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14263.2900 - acc: 0.9675 - f1: 0.9407\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13383.7224 - acc: 0.9702 - f1: 0.9434\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12730.1145 - acc: 0.9697 - f1: 0.9488\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12195.6786 - acc: 0.9737 - f1: 0.9515\n",
            "slice no:23\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12845.0870 - acc: 0.9749 - f1: 0.9522\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12149.4378 - acc: 0.9743 - f1: 0.9533\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11629.2598 - acc: 0.9739 - f1: 0.9562\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11210.6159 - acc: 0.9778 - f1: 0.9583\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10862.6115 - acc: 0.9763 - f1: 0.9603\n",
            "slice no:24\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16019.3061 - acc: 0.9769 - f1: 0.9558\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15283.6064 - acc: 0.9790 - f1: 0.9565\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14720.7352 - acc: 0.9772 - f1: 0.9587\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14269.3968 - acc: 0.9794 - f1: 0.9610\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13881.6144 - acc: 0.9808 - f1: 0.9630\n",
            "slice no:25\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13701.7390 - acc: 0.9814 - f1: 0.9646\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13205.7567 - acc: 0.9836 - f1: 0.9661\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12816.3179 - acc: 0.9802 - f1: 0.9640\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12501.7041 - acc: 0.9829 - f1: 0.9675\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12234.5004 - acc: 0.9822 - f1: 0.9667\n",
            "slice no:26\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15985.9972 - acc: 0.9831 - f1: 0.9647\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15524.6997 - acc: 0.9846 - f1: 0.9659\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15165.4750 - acc: 0.9830 - f1: 0.9664\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14858.8517 - acc: 0.9829 - f1: 0.9670\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14591.4538 - acc: 0.9837 - f1: 0.9679\n",
            "slice no:27\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13928.6117 - acc: 0.9860 - f1: 0.9673\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13582.1394 - acc: 0.9853 - f1: 0.9683\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13308.5928 - acc: 0.9854 - f1: 0.9710\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13086.7150 - acc: 0.9851 - f1: 0.9697\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12886.6746 - acc: 0.9860 - f1: 0.9709\n",
            "slice no:28\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 17281.4036 - acc: 0.9895 - f1: 0.9728\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16901.0650 - acc: 0.9878 - f1: 0.9712\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16589.3996 - acc: 0.9879 - f1: 0.9726\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16326.1289 - acc: 0.9900 - f1: 0.9744\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16091.0709 - acc: 0.9894 - f1: 0.9727\n",
            "slice no:29\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15573.1854 - acc: 0.9903 - f1: 0.9734\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15295.7204 - acc: 0.9897 - f1: 0.9754\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15070.8426 - acc: 0.9904 - f1: 0.9753\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14870.5730 - acc: 0.9901 - f1: 0.9771\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14689.7156 - acc: 0.9906 - f1: 0.9781\n",
            "slice no:30\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16619.4696 - acc: 0.9920 - f1: 0.9797\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16357.8859 - acc: 0.9918 - f1: 0.9812\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16129.8270 - acc: 0.9919 - f1: 0.9807\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15928.9501 - acc: 0.9923 - f1: 0.9804\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15747.8307 - acc: 0.9943 - f1: 0.9826\n",
            "slice no:31\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15234.7087 - acc: 0.9931 - f1: 0.9824\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15018.6259 - acc: 0.9937 - f1: 0.9835\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14836.0928 - acc: 0.9936 - f1: 0.9841\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14676.5511 - acc: 0.9948 - f1: 0.9853\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14531.9884 - acc: 0.9935 - f1: 0.9851\n",
            "slice no:32\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16482.5716 - acc: 0.9937 - f1: 0.9870\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16243.6903 - acc: 0.9953 - f1: 0.9874\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 16045.6565 - acc: 0.9953 - f1: 0.9885\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15867.0409 - acc: 0.9950 - f1: 0.9874\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15706.4846 - acc: 0.9947 - f1: 0.9873\n",
            "slice no:33\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15143.4548 - acc: 0.9942 - f1: 0.9876\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14950.4555 - acc: 0.9942 - f1: 0.9869\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14785.3403 - acc: 0.9953 - f1: 0.9881\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14641.1803 - acc: 0.9960 - f1: 0.9889\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14512.2672 - acc: 0.9950 - f1: 0.9887\n",
            "slice no:34\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15270.6915 - acc: 0.9968 - f1: 0.9905\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15080.5754 - acc: 0.9966 - f1: 0.9894\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14922.3261 - acc: 0.9968 - f1: 0.9911\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14782.1522 - acc: 0.9963 - f1: 0.9895\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14656.3668 - acc: 0.9962 - f1: 0.9912\n",
            "slice no:35\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14069.7918 - acc: 0.9968 - f1: 0.9902\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13922.9678 - acc: 0.9962 - f1: 0.9901\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13796.2364 - acc: 0.9970 - f1: 0.9905\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13680.5032 - acc: 0.9964 - f1: 0.9904\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13575.5640 - acc: 0.9968 - f1: 0.9911\n",
            "slice no:36\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14879.7781 - acc: 0.9974 - f1: 0.9918\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14736.0734 - acc: 0.9966 - f1: 0.9915\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14610.4323 - acc: 0.9976 - f1: 0.9926\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14497.3735 - acc: 0.9980 - f1: 0.9936\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14395.0709 - acc: 0.9973 - f1: 0.9918\n",
            "slice no:37\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13854.8442 - acc: 0.9976 - f1: 0.9927\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13742.0375 - acc: 0.9976 - f1: 0.9922\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13643.7742 - acc: 0.9974 - f1: 0.9917\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13557.9392 - acc: 0.9970 - f1: 0.9927\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13476.0607 - acc: 0.9985 - f1: 0.9930\n",
            "slice no:38\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13833.1576 - acc: 0.9974 - f1: 0.9929\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13717.7756 - acc: 0.9976 - f1: 0.9925\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13619.0986 - acc: 0.9978 - f1: 0.9927\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13531.2175 - acc: 0.9978 - f1: 0.9931\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13448.8397 - acc: 0.9974 - f1: 0.9930\n",
            "slice no:39\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12575.6271 - acc: 0.9976 - f1: 0.9921\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12479.7572 - acc: 0.9981 - f1: 0.9920\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12399.9594 - acc: 0.9982 - f1: 0.9928\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12328.9957 - acc: 0.9982 - f1: 0.9920\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12263.7069 - acc: 0.9979 - f1: 0.9929\n",
            "slice no:40\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13075.5067 - acc: 0.9972 - f1: 0.9930\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12981.8094 - acc: 0.9978 - f1: 0.9934\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12902.2295 - acc: 0.9980 - f1: 0.9937\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12831.0168 - acc: 0.9976 - f1: 0.9930\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12763.1967 - acc: 0.9987 - f1: 0.9948\n",
            "slice no:41\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12215.9389 - acc: 0.9980 - f1: 0.9929\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12135.9619 - acc: 0.9975 - f1: 0.9937\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12069.8383 - acc: 0.9987 - f1: 0.9932\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12006.9891 - acc: 0.9978 - f1: 0.9927\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11947.1839 - acc: 0.9982 - f1: 0.9947\n",
            "slice no:42\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12956.1293 - acc: 0.9985 - f1: 0.9945\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12871.4640 - acc: 0.9993 - f1: 0.9953\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12799.8972 - acc: 0.9986 - f1: 0.9951\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12735.9448 - acc: 0.9979 - f1: 0.9948\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12672.1778 - acc: 0.9986 - f1: 0.9945\n",
            "slice no:43\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12571.6999 - acc: 0.9986 - f1: 0.9950\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12494.0000 - acc: 0.9987 - f1: 0.9952\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12424.1857 - acc: 0.9992 - f1: 0.9949\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12362.0494 - acc: 0.9992 - f1: 0.9949\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12302.4651 - acc: 0.9987 - f1: 0.9953\n",
            "slice no:44\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12916.2243 - acc: 0.9990 - f1: 0.9944\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12830.6049 - acc: 0.9977 - f1: 0.9943\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12756.4071 - acc: 0.9983 - f1: 0.9952\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12688.4828 - acc: 0.9980 - f1: 0.9941\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12623.3001 - acc: 0.9987 - f1: 0.9951\n",
            "slice no:45\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12422.4963 - acc: 0.9986 - f1: 0.9952\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12346.6990 - acc: 0.9991 - f1: 0.9956\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12280.9914 - acc: 0.9985 - f1: 0.9950\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12222.6536 - acc: 0.9988 - f1: 0.9949\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12166.9391 - acc: 0.9991 - f1: 0.9951\n",
            "slice no:46\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12591.4394 - acc: 0.9975 - f1: 0.9952\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12512.8243 - acc: 0.9980 - f1: 0.9960\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12444.8163 - acc: 0.9980 - f1: 0.9952\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12382.5612 - acc: 0.9985 - f1: 0.9949\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12324.8815 - acc: 0.9976 - f1: 0.9949\n",
            "slice no:47\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12034.8414 - acc: 0.9976 - f1: 0.9948\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11970.8140 - acc: 0.9982 - f1: 0.9956\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11915.5851 - acc: 0.9984 - f1: 0.9956\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11863.7143 - acc: 0.9989 - f1: 0.9963\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11815.7137 - acc: 0.9990 - f1: 0.9953\n",
            "slice no:48\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12684.3014 - acc: 0.9984 - f1: 0.9953\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12617.7395 - acc: 0.9985 - f1: 0.9964\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12558.8901 - acc: 0.9979 - f1: 0.9956\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12503.4374 - acc: 0.9981 - f1: 0.9958\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12451.3150 - acc: 0.9984 - f1: 0.9952\n",
            "slice no:49\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12429.9764 - acc: 0.9987 - f1: 0.9962\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12366.4596 - acc: 0.9985 - f1: 0.9959\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12312.7700 - acc: 0.9987 - f1: 0.9960\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12261.4916 - acc: 0.9992 - f1: 0.9965\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12213.5363 - acc: 0.9982 - f1: 0.9960\n",
            "slice no:50\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12400.4710 - acc: 0.9988 - f1: 0.9965\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12342.6200 - acc: 0.9990 - f1: 0.9959\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12291.3008 - acc: 0.9988 - f1: 0.9955\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12244.7169 - acc: 0.9986 - f1: 0.9958\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12201.0562 - acc: 0.9989 - f1: 0.9962\n",
            "slice no:51\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11823.6069 - acc: 0.9974 - f1: 0.9950\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11771.2308 - acc: 0.9983 - f1: 0.9955\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11724.5118 - acc: 0.9980 - f1: 0.9956\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11681.9775 - acc: 0.9981 - f1: 0.9956\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11642.2361 - acc: 0.9981 - f1: 0.9953\n",
            "slice no:52\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11261.8885 - acc: 0.9977 - f1: 0.9943\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11212.9979 - acc: 0.9980 - f1: 0.9948\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11170.4878 - acc: 0.9977 - f1: 0.9943\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11131.6319 - acc: 0.9976 - f1: 0.9947\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11093.9791 - acc: 0.9980 - f1: 0.9950\n",
            "slice no:53\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10959.0975 - acc: 0.9974 - f1: 0.9943\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10915.2354 - acc: 0.9980 - f1: 0.9944\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10875.7565 - acc: 0.9969 - f1: 0.9941\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10838.9041 - acc: 0.9973 - f1: 0.9943\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10805.7703 - acc: 0.9987 - f1: 0.9960\n",
            "slice no:54\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11127.7463 - acc: 0.9967 - f1: 0.9939\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11079.5061 - acc: 0.9978 - f1: 0.9947\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11036.8596 - acc: 0.9974 - f1: 0.9942\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10997.5174 - acc: 0.9973 - f1: 0.9949\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10961.1980 - acc: 0.9974 - f1: 0.9950\n",
            "slice no:55\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11059.2281 - acc: 0.9961 - f1: 0.9925\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11010.2515 - acc: 0.9965 - f1: 0.9934\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10968.6452 - acc: 0.9961 - f1: 0.9930\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10930.6873 - acc: 0.9971 - f1: 0.9939\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10895.3593 - acc: 0.9961 - f1: 0.9930\n",
            "slice no:56\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11301.9119 - acc: 0.9966 - f1: 0.9927\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11251.5075 - acc: 0.9959 - f1: 0.9926\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11209.3854 - acc: 0.9961 - f1: 0.9936\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11170.3178 - acc: 0.9959 - f1: 0.9933\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11133.1524 - acc: 0.9954 - f1: 0.9918\n",
            "slice no:57\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11446.4827 - acc: 0.9946 - f1: 0.9920\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11398.9340 - acc: 0.9952 - f1: 0.9925\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11359.2197 - acc: 0.9944 - f1: 0.9920\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11322.3638 - acc: 0.9953 - f1: 0.9920\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11286.4349 - acc: 0.9946 - f1: 0.9928\n",
            "slice no:58\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11707.0351 - acc: 0.9944 - f1: 0.9924\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11660.2776 - acc: 0.9936 - f1: 0.9910\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11617.9363 - acc: 0.9947 - f1: 0.9916\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11580.1539 - acc: 0.9943 - f1: 0.9920\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11544.3337 - acc: 0.9941 - f1: 0.9919\n",
            "slice no:59\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12534.1230 - acc: 0.9891 - f1: 0.9877\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12482.8262 - acc: 0.9906 - f1: 0.9885\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12438.2653 - acc: 0.9889 - f1: 0.9865\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12396.3240 - acc: 0.9905 - f1: 0.9885\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12357.0975 - acc: 0.9906 - f1: 0.9884\n",
            "slice no:60\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13147.5798 - acc: 0.9871 - f1: 0.9856\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13090.3785 - acc: 0.9887 - f1: 0.9859\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13039.6920 - acc: 0.9858 - f1: 0.9840\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12993.5583 - acc: 0.9864 - f1: 0.9845\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12949.5257 - acc: 0.9866 - f1: 0.9851\n",
            "slice no:61\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12591.0223 - acc: 0.9834 - f1: 0.9812\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12538.4214 - acc: 0.9820 - f1: 0.9800\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12491.1638 - acc: 0.9833 - f1: 0.9810\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12447.8477 - acc: 0.9818 - f1: 0.9800\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12407.1322 - acc: 0.9821 - f1: 0.9804\n",
            "slice no:62\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13459.6750 - acc: 0.9766 - f1: 0.9738\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13404.4360 - acc: 0.9753 - f1: 0.9729\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13357.6133 - acc: 0.9757 - f1: 0.9729\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13312.3006 - acc: 0.9742 - f1: 0.9724\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13268.1748 - acc: 0.9767 - f1: 0.9731\n",
            "slice no:63\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13489.5244 - acc: 0.9665 - f1: 0.9647\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13432.3153 - acc: 0.9662 - f1: 0.9634\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13383.9918 - acc: 0.9664 - f1: 0.9654\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13339.4217 - acc: 0.9663 - f1: 0.9646\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13296.8548 - acc: 0.9666 - f1: 0.9643\n",
            "slice no:64\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14683.7320 - acc: 0.9576 - f1: 0.9552\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14622.2260 - acc: 0.9566 - f1: 0.9550\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14568.0510 - acc: 0.9578 - f1: 0.9567\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14516.2851 - acc: 0.9531 - f1: 0.9530\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14468.2770 - acc: 0.9557 - f1: 0.9537\n",
            "slice no:65\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14938.1375 - acc: 0.9468 - f1: 0.9461\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14869.7342 - acc: 0.9477 - f1: 0.9457\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14808.5537 - acc: 0.9463 - f1: 0.9466\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14752.4316 - acc: 0.9472 - f1: 0.9465\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14699.7376 - acc: 0.9488 - f1: 0.9458\n",
            "slice no:66\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14721.6319 - acc: 0.9432 - f1: 0.9422\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14658.7196 - acc: 0.9430 - f1: 0.9425\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14603.4526 - acc: 0.9432 - f1: 0.9427\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14552.2530 - acc: 0.9447 - f1: 0.9446\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14503.0600 - acc: 0.9411 - f1: 0.9417\n",
            "slice no:67\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14477.5859 - acc: 0.9360 - f1: 0.9356\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14418.9777 - acc: 0.9362 - f1: 0.9365\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14367.3221 - acc: 0.9370 - f1: 0.9370\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14318.0779 - acc: 0.9381 - f1: 0.9376\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14270.9227 - acc: 0.9361 - f1: 0.9353\n",
            "slice no:68\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14585.6361 - acc: 0.9326 - f1: 0.9320\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14529.5463 - acc: 0.9327 - f1: 0.9324\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14478.7124 - acc: 0.9331 - f1: 0.9339\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14431.6707 - acc: 0.9342 - f1: 0.9347\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14387.5627 - acc: 0.9353 - f1: 0.9339\n",
            "slice no:69\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14347.8904 - acc: 0.9297 - f1: 0.9294\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14294.5463 - acc: 0.9298 - f1: 0.9307\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14248.2229 - acc: 0.9267 - f1: 0.9296\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14205.1446 - acc: 0.9275 - f1: 0.9295\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14162.9699 - acc: 0.9296 - f1: 0.9300\n",
            "slice no:70\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14611.0990 - acc: 0.9222 - f1: 0.9229\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14558.5755 - acc: 0.9221 - f1: 0.9222\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14511.5251 - acc: 0.9222 - f1: 0.9247\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14467.3227 - acc: 0.9241 - f1: 0.9240\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14426.0415 - acc: 0.9222 - f1: 0.9225\n",
            "slice no:71\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14157.8503 - acc: 0.9171 - f1: 0.9177\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14104.2336 - acc: 0.9173 - f1: 0.9185\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14058.0479 - acc: 0.9194 - f1: 0.9189\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14016.7044 - acc: 0.9194 - f1: 0.9190\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13976.7150 - acc: 0.9170 - f1: 0.9183\n",
            "slice no:72\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14489.1310 - acc: 0.9135 - f1: 0.9133\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14435.6418 - acc: 0.9137 - f1: 0.9150\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14390.2310 - acc: 0.9156 - f1: 0.9147\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14346.0935 - acc: 0.9151 - f1: 0.9140\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14304.3182 - acc: 0.9147 - f1: 0.9147\n",
            "slice no:73\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14311.4513 - acc: 0.9102 - f1: 0.9097\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14260.3480 - acc: 0.9095 - f1: 0.9090\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14215.6851 - acc: 0.9108 - f1: 0.9109\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14173.6981 - acc: 0.9084 - f1: 0.9093\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14135.2026 - acc: 0.9118 - f1: 0.9127\n",
            "slice no:74\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14901.4030 - acc: 0.9024 - f1: 0.9015\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14846.2551 - acc: 0.9026 - f1: 0.9017\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14796.1008 - acc: 0.9027 - f1: 0.9020\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14748.9423 - acc: 0.9040 - f1: 0.9031\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14704.7768 - acc: 0.9033 - f1: 0.9013\n",
            "slice no:75\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14764.6435 - acc: 0.8996 - f1: 0.8974\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14711.3435 - acc: 0.8977 - f1: 0.8964\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14663.7526 - acc: 0.9004 - f1: 0.8993\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14619.0462 - acc: 0.8982 - f1: 0.8977\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14576.5299 - acc: 0.8982 - f1: 0.8973\n",
            "slice no:76\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15174.8108 - acc: 0.8935 - f1: 0.8903\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15116.0983 - acc: 0.8939 - f1: 0.8919\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15063.2812 - acc: 0.8935 - f1: 0.8910\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15013.5206 - acc: 0.8939 - f1: 0.8919\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14966.6424 - acc: 0.8930 - f1: 0.8914\n",
            "slice no:77\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14760.4007 - acc: 0.8892 - f1: 0.8878\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14706.8196 - acc: 0.8911 - f1: 0.8893\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14658.3706 - acc: 0.8900 - f1: 0.8882\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14613.3325 - acc: 0.8907 - f1: 0.8887\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14571.4615 - acc: 0.8904 - f1: 0.8892\n",
            "slice no:78\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14951.1158 - acc: 0.8851 - f1: 0.8853\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14901.5639 - acc: 0.8876 - f1: 0.8849\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14856.6729 - acc: 0.8860 - f1: 0.8860\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14815.1455 - acc: 0.8867 - f1: 0.8855\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14776.2934 - acc: 0.8867 - f1: 0.8855\n",
            "slice no:79\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14979.6439 - acc: 0.8836 - f1: 0.8816\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14932.2669 - acc: 0.8840 - f1: 0.8823\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14889.4990 - acc: 0.8845 - f1: 0.8823\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14849.8420 - acc: 0.8850 - f1: 0.8835\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14812.4499 - acc: 0.8840 - f1: 0.8829\n",
            "slice no:80\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15268.5384 - acc: 0.8829 - f1: 0.8815\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15219.2699 - acc: 0.8813 - f1: 0.8792\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15176.2202 - acc: 0.8812 - f1: 0.8795\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15135.2129 - acc: 0.8816 - f1: 0.8806\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15096.6610 - acc: 0.8822 - f1: 0.8808\n",
            "slice no:81\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15420.7117 - acc: 0.8778 - f1: 0.8757\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15375.8499 - acc: 0.8790 - f1: 0.8773\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15334.6982 - acc: 0.8780 - f1: 0.8763\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15296.1866 - acc: 0.8779 - f1: 0.8777\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15260.0211 - acc: 0.8801 - f1: 0.8779\n",
            "slice no:82\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15376.1002 - acc: 0.8746 - f1: 0.8706\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15330.9482 - acc: 0.8734 - f1: 0.8724\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15291.5938 - acc: 0.8746 - f1: 0.8735\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15254.8763 - acc: 0.8757 - f1: 0.8730\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15220.2576 - acc: 0.8745 - f1: 0.8723\n",
            "slice no:83\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15118.3655 - acc: 0.8704 - f1: 0.8683\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15076.8232 - acc: 0.8732 - f1: 0.8711\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15039.5035 - acc: 0.8722 - f1: 0.8695\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 15005.7026 - acc: 0.8717 - f1: 0.8697\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14973.3073 - acc: 0.8730 - f1: 0.8692\n",
            "slice no:84\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14747.0028 - acc: 0.8691 - f1: 0.8659\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14704.7664 - acc: 0.8688 - f1: 0.8672\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14667.1231 - acc: 0.8688 - f1: 0.8665\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14632.2005 - acc: 0.8690 - f1: 0.8675\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14598.5440 - acc: 0.8702 - f1: 0.8677\n",
            "slice no:85\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14519.7990 - acc: 0.8654 - f1: 0.8620\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14477.4630 - acc: 0.8653 - f1: 0.8624\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14438.7801 - acc: 0.8661 - f1: 0.8630\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14403.1397 - acc: 0.8652 - f1: 0.8624\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14369.9873 - acc: 0.8668 - f1: 0.8633\n",
            "slice no:86\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14575.3616 - acc: 0.8645 - f1: 0.8613\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14531.0478 - acc: 0.8624 - f1: 0.8615\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14491.9544 - acc: 0.8638 - f1: 0.8617\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14455.6550 - acc: 0.8640 - f1: 0.8605\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14421.5016 - acc: 0.8651 - f1: 0.8625\n",
            "slice no:87\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14510.8465 - acc: 0.8602 - f1: 0.8577\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14467.9682 - acc: 0.8623 - f1: 0.8591\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14429.1567 - acc: 0.8613 - f1: 0.8585\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14392.6005 - acc: 0.8607 - f1: 0.8573\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14358.2320 - acc: 0.8612 - f1: 0.8596\n",
            "slice no:88\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14827.3380 - acc: 0.8566 - f1: 0.8538\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14785.6204 - acc: 0.8573 - f1: 0.8558\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14747.9765 - acc: 0.8588 - f1: 0.8565\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14712.7543 - acc: 0.8579 - f1: 0.8548\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14679.4529 - acc: 0.8591 - f1: 0.8573\n",
            "slice no:89\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 14031.0941 - acc: 0.8560 - f1: 0.8528\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13992.1510 - acc: 0.8561 - f1: 0.8546\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13957.6299 - acc: 0.8570 - f1: 0.8550\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13925.9729 - acc: 0.8563 - f1: 0.8539\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13895.4388 - acc: 0.8578 - f1: 0.8559\n",
            "slice no:90\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13871.7910 - acc: 0.8566 - f1: 0.8552\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13836.3083 - acc: 0.8570 - f1: 0.8562\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13804.7069 - acc: 0.8570 - f1: 0.8568\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13774.1964 - acc: 0.8555 - f1: 0.8551\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13745.1822 - acc: 0.8568 - f1: 0.8562\n",
            "slice no:91\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13773.5479 - acc: 0.8569 - f1: 0.8561\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13739.0551 - acc: 0.8575 - f1: 0.8562\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13708.4396 - acc: 0.8575 - f1: 0.8567\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13679.6993 - acc: 0.8577 - f1: 0.8569\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13652.7300 - acc: 0.8565 - f1: 0.8561\n",
            "slice no:92\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13822.2767 - acc: 0.8557 - f1: 0.8537\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13789.0191 - acc: 0.8550 - f1: 0.8539\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13759.7271 - acc: 0.8556 - f1: 0.8546\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13732.4034 - acc: 0.8568 - f1: 0.8549\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13706.1649 - acc: 0.8550 - f1: 0.8536\n",
            "slice no:93\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13417.7389 - acc: 0.8572 - f1: 0.8554\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13386.8086 - acc: 0.8590 - f1: 0.8565\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13359.0851 - acc: 0.8566 - f1: 0.8548\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13333.9187 - acc: 0.8573 - f1: 0.8547\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13310.0096 - acc: 0.8571 - f1: 0.8557\n",
            "slice no:94\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13505.0111 - acc: 0.8577 - f1: 0.8554\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13474.0963 - acc: 0.8570 - f1: 0.8538\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13446.6998 - acc: 0.8600 - f1: 0.8547\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13420.9288 - acc: 0.8585 - f1: 0.8560\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13396.4502 - acc: 0.8585 - f1: 0.8543\n",
            "slice no:95\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13075.0893 - acc: 0.8597 - f1: 0.8541\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13045.9098 - acc: 0.8606 - f1: 0.8560\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13019.9463 - acc: 0.8609 - f1: 0.8566\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12995.3493 - acc: 0.8606 - f1: 0.8561\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12971.9033 - acc: 0.8608 - f1: 0.8547\n",
            "slice no:96\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13118.9710 - acc: 0.8576 - f1: 0.8524\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13088.8291 - acc: 0.8570 - f1: 0.8518\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13062.1707 - acc: 0.8593 - f1: 0.8549\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13037.5562 - acc: 0.8586 - f1: 0.8530\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 13014.0590 - acc: 0.8581 - f1: 0.8528\n",
            "slice no:97\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12899.5613 - acc: 0.8602 - f1: 0.8559\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12869.5960 - acc: 0.8607 - f1: 0.8549\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12844.0691 - acc: 0.8587 - f1: 0.8549\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12820.1854 - acc: 0.8597 - f1: 0.8547\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12797.6014 - acc: 0.8598 - f1: 0.8541\n",
            "slice no:98\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12577.0697 - acc: 0.8611 - f1: 0.8550\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12547.4383 - acc: 0.8616 - f1: 0.8577\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12521.5877 - acc: 0.8604 - f1: 0.8558\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12497.5414 - acc: 0.8605 - f1: 0.8558\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12474.6829 - acc: 0.8601 - f1: 0.8566\n",
            "slice no:99\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12325.7929 - acc: 0.8604 - f1: 0.8566\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12298.9333 - acc: 0.8603 - f1: 0.8567\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12275.4004 - acc: 0.8612 - f1: 0.8575\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12253.3561 - acc: 0.8607 - f1: 0.8582\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12232.7469 - acc: 0.8618 - f1: 0.8567\n",
            "slice no:100\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12710.2854 - acc: 0.8602 - f1: 0.8565\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12681.2237 - acc: 0.8586 - f1: 0.8547\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12655.1744 - acc: 0.8616 - f1: 0.8579\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12631.6497 - acc: 0.8598 - f1: 0.8569\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12609.3157 - acc: 0.8624 - f1: 0.8577\n",
            "slice no:101\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12356.3444 - acc: 0.8611 - f1: 0.8574\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12328.7644 - acc: 0.8623 - f1: 0.8569\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12304.6888 - acc: 0.8624 - f1: 0.8587\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12282.5086 - acc: 0.8617 - f1: 0.8571\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 12261.5601 - acc: 0.8640 - f1: 0.8596\n",
            "slice no:102\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11891.9253 - acc: 0.8666 - f1: 0.8632\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11866.3159 - acc: 0.8677 - f1: 0.8629\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11844.4837 - acc: 0.8672 - f1: 0.8637\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11824.4120 - acc: 0.8668 - f1: 0.8629\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11805.4023 - acc: 0.8682 - f1: 0.8642\n",
            "slice no:103\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11088.0805 - acc: 0.8711 - f1: 0.8672\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11063.4215 - acc: 0.8697 - f1: 0.8659\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11042.5095 - acc: 0.8705 - f1: 0.8671\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11023.5098 - acc: 0.8702 - f1: 0.8668\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 11005.9303 - acc: 0.8700 - f1: 0.8681\n",
            "slice no:104\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10880.6264 - acc: 0.8724 - f1: 0.8688\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10856.4668 - acc: 0.8720 - f1: 0.8674\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10835.6902 - acc: 0.8719 - f1: 0.8673\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10816.7353 - acc: 0.8730 - f1: 0.8677\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10798.9894 - acc: 0.8725 - f1: 0.8676\n",
            "slice no:105\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10831.2722 - acc: 0.8749 - f1: 0.8697\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10809.1736 - acc: 0.8743 - f1: 0.8703\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10789.5866 - acc: 0.8748 - f1: 0.8708\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10771.4249 - acc: 0.8745 - f1: 0.8705\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10754.8495 - acc: 0.8755 - f1: 0.8714\n",
            "slice no:106\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10907.7761 - acc: 0.8770 - f1: 0.8730\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10886.1745 - acc: 0.8777 - f1: 0.8744\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10866.9298 - acc: 0.8767 - f1: 0.8727\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10848.6044 - acc: 0.8770 - f1: 0.8733\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10831.4520 - acc: 0.8770 - f1: 0.8734\n",
            "slice no:107\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10650.5563 - acc: 0.8797 - f1: 0.8759\n",
            "Epoch 2/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10629.2119 - acc: 0.8784 - f1: 0.8749\n",
            "Epoch 3/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10609.8780 - acc: 0.8779 - f1: 0.8746\n",
            "Epoch 4/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10592.6683 - acc: 0.8785 - f1: 0.8750\n",
            "Epoch 5/5\n",
            "10752/10752 [==============================] - 27s 3ms/sample - loss: 10576.0278 - acc: 0.8791 - f1: 0.8751\n",
            "slice no:108\n",
            "Train on 10752 samples\n",
            "Epoch 1/5\n",
            " 9344/10752 [=========================>....] - ETA: 3s - loss: 10393.4303 - acc: 0.8824 - f1: 0.8791"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTvOBHDzMZ8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fc6f3ca3-2dac-46ee-b15f-79ce281fca3c"
      },
      "source": [
        "model = tf.keras.models.load_model('trial_InputCascade_acc.h5', custom_objects={'f1': f1})\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjy-lZVMM3kJ",
        "colab_type": "code",
        "outputId": "e6ad92ec-798b-4820-f16f-c3d942da7d68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = '/content/drive/My Drive/BRATS-2/Image_Data/HG/0003'\n",
        "p = os.listdir(path)\n",
        "p.sort(key=str.lower)\n",
        "arr = []\n",
        "for i in range(len(p)):\n",
        "  if(i != 4):\n",
        "    p1 = os.listdir(path+'/'+p[i])\n",
        "    p1.sort()\n",
        "    img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[-1])\n",
        "    arr.append(sitk.GetArrayFromImage(img))\n",
        "  else:\n",
        "    p1 = os.listdir(path+'/'+p[i])\n",
        "    img = sitk.ReadImage(path+'/'+p[i]+'/'+p1[0])\n",
        "    Y_labels = sitk.GetArrayFromImage(img)    \n",
        "data = np.zeros((Y_labels.shape[1],Y_labels.shape[0],Y_labels.shape[2],4))\n",
        "for i in range(Y_labels.shape[1]):\n",
        "  data[i,:,:,0] = arr[0][:,i,:]\n",
        "  data[i,:,:,1] = arr[1][:,i,:]\n",
        "  data[i,:,:,2] = arr[2][:,i,:]\n",
        "  data[i,:,:,3] = arr[3][:,i,:]\n",
        "info = []\n",
        " \n",
        "    \n",
        "d = data_gen(data,Y_labels,113,1)\n",
        "if(len(d) != 0):\n",
        "  y = np.zeros((d[2].shape[0],1,1,5))\n",
        "  for j in range(y.shape[0]):\n",
        "    y[j,:,:,d[2][j]] = 1\n",
        "  X1 = d[0]\n",
        "  X2 = d[1]\n",
        "  pred = model.predict([X1,X2],batch_size = 256) \n",
        "  pred = np.around(pred)\n",
        "  #print(pred.shape)\n",
        "  pred1 = np.argmax(pred.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
        "  y2 = np.argmax(y.reshape(y.shape[0],5)[:,1:4],axis = 1)\n",
        "  f1 = metrics.f1_score(y2,pred1,average='micro')\n",
        "  print(f1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9231505102040817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUJPW_s-Rbli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHuy6Eo-iCO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# m0.compile(optimizer='sgd',loss='categorical_hinge',metrics=[f1_score])\n",
        "# m0.save('trial_0001_twopathcnn_f1.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6li6W7egTQEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKt8BL36TQtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8U0nPsKSm7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMRT_nNUF6nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfY_gPYavnE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec4vdoZOS4_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaGVclYpTRx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkbp6sv-Wzqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAbxx1isoA2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}